**1. 컴퓨터 부팅 과정과 I/O 처리 방식 모범 답안**

- **부팅 절차:**
    
    1. **CPU 초기화 및 BIOS/UEFI 실행:** 전원이 인가되면 CPU는 스스로 초기화하고 이상 유무를 확인한 뒤, 프로그램 카운터(PC)를 특정 주소(예: `0xfffffff0`)로 옮겨 해당 위치의 명령어를 실행합니다. 이 명령어는 시스템 펌웨어인 BIOS 또는 UEFI 코드의 시작 주소로 점프합니다.
    2. **POST 및 부트 장치 검색:** BIOS/UEFI는 컴퓨터 동작에 필수적인 인터페이스(CPU, 메모리, 기본 I/O 장치 등)의 상태를 확인하고 초기화하는 POST(Power On Self-Test)를 수행합니다. 이후 설정된 순서에 따라 부팅 가능한 디스크(부트 장치)를 검색합니다.
    3. **부트 로더 로딩 및 제어권 이전:** BIOS/UEFI는 검색된 부트 장치의 첫 섹터인 MBR(Master Boot Record) 또는 EFI 시스템 파티션(ESP)을 메모리에 로드하여 실행합니다. 이 MBR 또는 ESP에는 부트 로더(예: LILO, GRUB)의 첫 번째 단계 코드가 포함되어 있습니다. 이 코드가 실행되면 BIOS/UEFI는 부트 로더에게 시스템 제어권을 이전합니다.
    4. **부트 로더 실행 및 커널 로딩:** 제어권을 받은 부트 로더의 초기 코드는 부트 로더의 나머지 부분을 메모리에 로드하고 실행합니다. 완전히 실행된 부트 로더는 디스크에서 압축된 형태의 운영체제 커널 파일을 찾아 메모리에 로드합니다.
    5. **커널 초기화:** 메모리에 로드된 커널은 스스로 압축을 해제하고, 압축 해제된 커널 코드에게 제어권을 이전하며 커널 초기화 단계로 진입합니다.
    
    - **부트 로더 역할:** 부트 로더는 BIOS/UEFI로부터 제어권을 받아, 파일 시스템을 인식하고 사용자가 선택하거나 설정된 운영체제의 커널 이미지를 디스크에서 찾아 메모리에 로드하는 핵심적인 역할을 수행합니다.
    - **MBR/ESP 차이점:** MBR은 전통적인 BIOS 환경에서 사용되는 부트 장치의 첫 번째 섹터로, 파티션 테이블 정보와 부트 로더의 초기 코드를 담고 있습니다. ESP는 최신 UEFI 환경에서 사용되는 별도의 파티션으로, GPT 파티션 테이블과 함께 사용되며 부트 로더 실행 파일(`.efi`)을 저장합니다. UEFI는 MBR보다 더 유연하고 현대적인 부팅 방식을 제공하며 ESP에서 직접 부트 로더를 실행합니다.
- **I/O 처리 방식 비교 및 DMA:**
    
    - **폴링(Polling) vs. 인터럽트(Interrupt):**
        - **폴링:** CPU가 주기적으로 I/O 장치의 상태 레지스터를 직접 확인하여 작업 완료 여부를 체크하는 방식입니다. CPU가 계속 상태를 확인해야 하므로 CPU 자원이 낭비될 수 있습니다.
        - **인터럽트:** I/O 장치가 작업을 완료하면 I/O 컨트롤러가 CPU에게 인터럽트 신호(성공/실패 여부 및 결과 포함)를 보냅니다. CPU는 하던 작업을 잠시 멈추고 해당 인터럽트를 처리(I/O 작업 결과 처리)한 후 원래 작업으로 복귀합니다. 폴링보다 CPU 효율성이 높습니다.
    - **DMA (Direct Memory Access):**
        - **동작 원리:** 인터럽트 방식은 데이터 전송 자체에도 CPU의 개입이 필요할 수 있어 병목이 발생할 수 있습니다. 특히 데이터 크기가 클 때 비효율적입니다. DMA는 이를 해결하기 위해 등장했습니다. CPU는 DMA 컨트롤러에게 메모리 접근 권한을 위임하고 데이터 전송 시작을 지시합니다. DMA 컨트롤러는 CPU의 개입 없이 I/O 장치와 메모리 사이에서 직접 데이터 블록(버퍼)을 전송합니다.
        - **장점:** 데이터 전송이 완료되면 디스크 컨트롤러(또는 DMA 컨트롤러)가 CPU에게 인터럽트를 _한 번만_ 발생시켜 완료를 알립니다. 이를 통해 대용량 데이터 전송 중 CPU가 다른 작업을 효율적으로 수행할 수 있게 하여 시스템 전체 성능을 향상시킵니다.

---

**2. CPU 스케줄링 알고리즘 비교 분석 모범 답안**

- **FCFS (First Come First Serve):**
    
    - **작동 방식:** 가장 간단한 스케줄링 알고리즘으로, 준비 큐(Ready Queue)에 도착한 순서대로 프로세스에 CPU를 할당합니다. 비선점형(Non-preemptive) 방식입니다.
    - **장점:** 구현이 간단하고 모든 프로세스가 언젠가는 실행되므로 기아(Starvation) 문제가 발생하지 않아 공평(Fair)합니다.
    - **Convoy Effect:** CPU 사용 시간이 긴 프로세스가 먼저 CPU를 할당받으면, 이후에 도착한 CPU 사용 시간이 짧은 여러 프로세스들이 해당 긴 프로세스가 끝날 때까지 계속 기다려야 하는 현상입니다. 이로 인해 평균 대기 시간이 길어지고 시스템 성능(처리율)이 저하되는 문제가 발생합니다.
- **SJF (Shortest Job First):**
    
    - **Convoy Effect 해결:** SJF는 준비 큐에 있는 프로세스들 중 예상 CPU 버스트(Burst) 시간이 가장 짧은 프로세스에게 CPU를 먼저 할당합니다. 이를 통해 FCFS의 Convoy Effect, 즉 긴 작업이 짧은 작업들을 지연시키는 문제를 완화하여 평균 대기 시간을 최소화(Optimal)하려 합니다.
    - **구현 어려움 및 문제점:**
        - **예측 불가능성:** 실제로는 다음 CPU 버스트 시간을 정확히 예측하는 것이 거의 불가능합니다. 특히 분기 등이 많은 프로그램은 예측이 더욱 어렵습니다. 필기 자료에 따르면 예측 알고리즘 오차도 심해 사용이 불가하다고 언급됩니다. 따라서 순수한 SJF는 이론적이며 실제 구현은 어렵습니다.
        - **Starvation (기아):** CPU 버스트 시간이 긴 프로세스는 자신보다 짧은 프로세스들이 계속해서 도착하는 경우, CPU를 할당받지 못하고 무한정 대기하는 기아 상태에 빠질 수 있습니다.

---

**3. 프로세스 상태 전이 및 우선순위 스케줄링 문제 해결 모범 답안**

- **프로세스 상태 전이:**
    
    - 프로세스는 운영체제 내에서 여러 상태를 거칩니다. 주요 상태는 다음과 같습니다.
        - **new:** 프로세스가 생성되는 중인 상태입니다.
        - **ready:** 프로세스가 CPU를 할당받아 실행될 준비가 완료된 상태로, 메모리 등 필요한 자원을 할당받고 스케줄러의 선택을 기다립니다.
        - **running:** 프로세스가 실제로 CPU를 점유하고 명령어를 실행 중인 상태입니다.
        - **waiting:** 프로세스가 특정 이벤트(예: I/O 작업 완료, 시그널 수신 등)를 기다리며 실행을 멈춘 상태입니다.
        - **terminated:** 프로세스가 실행을 완료하고 종료된 상태입니다.
    - **상태 전이:**
        - `new` -> `ready`: 프로세스 생성이 완료되어 스케줄링될 준비가 되면 이동합니다.
        - `ready` -> `running`: CPU 스케줄러가 해당 프로세스를 선택(dispatch)하면 이동합니다.
        - `running` -> `waiting`: 프로세스가 I/O 요청이나 다른 이벤트를 기다려야 할 때 (예: Trap, System Call 발생 시) 이동합니다.
        - `running` -> `ready`: 할당된 타임 슬라이스가 만료되거나 (Round-Robin 등), 우선순위가 높은 프로세스가 등장하여 선점(preemption)될 때, 또는 인터럽트(Interrupt) 발생 후 처리 완료 시 이동합니다.
        - `waiting` -> `ready`: 기다리던 I/O 작업이 완료되거나 이벤트가 발생하면 이동합니다.
        - `running` -> `terminated`: 프로세스 실행이 완료되면 이동합니다.
- **우선순위 스케줄링 문제 및 Aging:**
    
    - **Starvation 문제:** 우선순위 스케줄링은 각 프로세스에 부여된 우선순위에 따라 CPU를 할당합니다. 이 방식에서는 우선순위가 낮은 프로세스는 우선순위가 높은 프로세스들이 계속해서 시스템에 도착하는 경우, CPU를 할당받지 못하고 무한정 대기하는 기아(Starvation) 상태에 빠질 수 있습니다. 필기 자료에 따르면 어떤 가중치를 사용하든 계산 불가능(Starvation 발생 가능)하다고 언급됩니다.
    - **Aging 기법:** Aging은 Starvation 문제를 해결하기 위한 기법입니다. 오랫동안 대기하고 있는 프로세스의 우선순위를 시간이 지남에 따라 점진적으로 높여주는 방식입니다. 이렇게 하면 아무리 낮은 우선순위를 가진 프로세스라도 결국에는 우선순위가 충분히 높아져 CPU를 할당받을 기회를 얻게 됩니다. 필기 자료에 따르면 Aging을 통해 우선순위 기반 알고리즘의 Starvation은 해결 가능하다고 합니다.

---

**4. CPU 명령어 처리 기법 및 병렬성 모범 답안**

- **RISC vs. CISC:**
    
    - **설계 철학 차이:**
        - **CISC (Complex Instruction Set Computer):** 하나의 명령어가 복잡하고 강력한 기능을 수행하도록 설계되었습니다. 하드웨어적으로 여러 기본 동작을 하나의 명령어로 처리하여, 이론적으로는 적은 수의 명령어로 프로그램을 작성할 수 있게 합니다. 하지만 명령어 길이가 가변적이고 디코딩이 복잡하며, 파이프라이닝에 불리할 수 있습니다. (예: Intel, AMD)
        - **RISC (Reduced Instruction Set Computer):** 자주 사용되는 간단한 명령어들로 명령어 집합을 구성하고, 명령어 길이를 고정하며 디코딩을 단순화합니다. 복잡한 연산은 간단한 명령어들의 조합으로 처리하며, 컴파일러의 역할이 중요해집니다. 파이프라이닝에 유리하도록 설계되었습니다. (예: ARM)
    - **파이프라이닝 (Pipelining):**
        - **기본 단계 및 원리:** RISC 프로세서에서 명령어 처리 속도를 높이는 기법입니다. 하나의 명령어를 처리하는 과정을 여러 단계(예: **Fetch**(명령어 가져오기), **Decode**(명령어 해석), **Execute**(실행), **Write Back**(결과 저장))로 나누고, 각 단계를 동시에 다른 명령어에 대해 처리하는 방식입니다. 예를 들어, 첫 번째 명령어가 Decode 단계에 있을 때, 두 번째 명령어는 Fetch 단계를 수행하는 식으로 명령어 처리 단계들을 겹쳐서 실행하여 전체 처리 시간을 단축합니다.
        - **효율성 저하:** 명령어 간 의존성(한 명령어의 결과가 다음 명령어의 입력으로 필요)이 있거나, 분기(branch) 명령어로 인해 다음에 실행할 명령어를 예측하기 어려운 경우 파이프라인이 잠시 멈추거나(stall), 잘못 예측된 명령어들을 폐기해야 하므로 효율성이 떨어질 수 있습니다. 또한, 각 단계의 처리 시간이 불균형하게 길 경우에도 병목 현상이 발생하여 효율이 저하될 수 있습니다.
- **명령어 수준 병렬성 (ILP):**
    
    - **슈퍼스칼라 (Superscalar):** 하드웨어(HW) 레벨에서 동시에 실행 가능한 독립적인 명령어를 찾아 여러 개의 실행 유닛을 사용하여 병렬로 처리하는 기법입니다. 예를 들어, 두 연산(명령어) 간에 데이터 의존성이 없다면 하드웨어가 이를 감지하고 동시에 실행합니다. (예: Intel CPU)
    - **VLIW (Very Long Instruction Word):** 컴파일러가 컴파일 시점에 미리 독립적으로 실행 가능한 명령어들을 찾아 하나의 매우 긴 명령어(VLIW) 패킷으로 묶어줍니다. 하드웨어는 이 VLIW 패킷을 받아 안에 포함된 여러 명령어를 동시에 병렬로 실행합니다. 병렬성 분석의 부담을 하드웨어 대신 컴파일러가 지는 방식입니다.

---

**5. 다중 처리기 환경에서의 스케줄링 고려사항 모범 답안**

- **부하 균등 (Load Balancing):**
    
    - **필요성:** 다중 처리기(Multi-Processor) 시스템에서 특정 코어(CPU)에만 작업이 몰리고 다른 코어는 유휴 상태가 되는 것을 방지하여, 모든 코어를 효율적으로 사용하고 전체 시스템 처리율을 높이기 위해 필요합니다.
    - **Push Migration:** 부하가 많은(연산이 몰린) 코어가 자신의 작업 큐에 있는 일부 작업을 부하가 적은 다른 코어로 직접 보내는(push) 방식입니다. 단점으로는, 부하가 많은 코어가 로드 밸런싱 작업까지 수행해야 하므로 추가적인 오버헤드가 발생할 수 있습니다.
    - **Pull Migration:** 부하가 적거나 유휴 상태인 코어가 다른 (주로 부하가 많은) 코어의 작업 큐에서 작업을 가져오는(pull) 방식입니다. 단점으로는, 작업을 가져오려는 코어가 다른 코어의 상태를 정확히 알기 어려워 비효율적인 시도를 하거나 통신 오버헤드가 발생할 수 있습니다.
- **프로세서 선호도 (Processor Affinity):**
    
    - **개념:** 프로세스가 특정 코어에서 실행될 때 해당 코어의 캐시 메모리에 관련 데이터가 저장됩니다. 만약 이 프로세스가 다른 코어로 이동(migration)되면 캐시된 데이터를 사용할 수 없어 캐시 미스(cache miss)가 발생하고 성능이 저하될 수 있습니다. 프로세서 선호도는 이러한 캐시 효율성을 유지하기 위해 프로세스를 가급적 이전에 실행되었던 코어에 계속 할당하려는 경향 또는 정책을 의미합니다. (특히 Common Ready Queue 사용 시 고려됨)
    - **Soft Affinity vs. Hard Affinity (필기 자료 기반):**
        - **Soft Affinity:** 운영체제가 프로세스를 가능한 한 원래 실행되던 코어에서 계속 실행시키려고 **노력**하는 방식입니다. 
        - **Hard Affinity:** 운영체제나 사용자가 프로세스가 실행될 수 있는 코어를 명시적으로 **지정**하는 방식입니다. 
    - **성능 영향:** 프로세서 선호도를 유지하면 캐시 히트율(cache hit rate)을 높여 메모리 접근 시간을 줄이고 프로세스 실행 속도를 향상시킬 수 있습니다. 반면, 선호도를 너무 강하게 유지하면 부하 균등이 제대로 이루어지지 않아 특정 코어에 부하가 집중될 수 있습니다.